Synthetic Benchmark for ARGO
==================

* Introduction

This is a simulated somatic whole genome sequencing (WGS) sample to use for
technical benchmarking. The purpose is to test that pipelines go end-to-end and
that the results are reasonable. It's not intended to evaluate the precision
and sensitivity of tools, since it has a number of limitations. The samples are
not full WGS but a reduced size sample.

* Layout of the data

In the benchmark bundle you can find the normal and tumor samples in FASTQ
format, the BAM files resulting from alignment using GATK best practices
(including base-recalibration; using the Rbbt workflow
https://github.com/Rbbt-Workflows/HTS), and the truth sets of germline and
somatic variants.

In addition to these sets, we have included minified versions of the hg38
reference and main population resources to help speed up tests. These are not
required as the samples can be analyzed with the regular reference sets.

* How it was built

The dataset was built with the Rbbt workflow
https://github.com/Rbbt-Workflows/HTSBenchmark

A germline genotype is generated from 1000 genomes using an stochastic process
based on European allele frequencies. A somatic genotype is generated by
combining all the mutations from donors of a particular PCAWG study
(Bladder-TCC by default) and selecting randomly a certain number of mutations
(20 million by default) to control mutation density. 

A minified genotype is generated by selecting a truncation point for each
chromosome that guarantees that a minimum number of somatic mutations are
covered (100 by default). Those truncation points are used to filter the two
simulated genotypes described above.

To generate the simulated data we start by produced a truncated version of the
hg38 reference, using the same truncation points. We then use the NEAT GenReads
tool to simulate a 'normal' sample, using the germline genotype, and a 'tumor'
sample combining the same germline genotype with the somatic genotype. Since
the reference has been truncated, NEAT GenReads only simulates reads from the
initial portions of the chromosomes, leading to a much reduced sample FASTQ
files.

Both samples are process by the alignment pipeline of Rbbt, as decribed above,
to generate the align BAM files. Which are bundled along with the FASTQ files,
the two simulated genotypes and the minified reference.
